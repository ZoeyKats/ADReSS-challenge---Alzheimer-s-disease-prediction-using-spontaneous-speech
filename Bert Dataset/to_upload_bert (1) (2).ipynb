{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf07a99-0a20-4331-96b4-205d201199c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zoika\\anaconda3\\envs\\tf_gpu_38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from transformers import TFBertModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from transformers import TFAutoModel, AutoTokenizer, BertForPreTraining\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from transformers import TFBertModel\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import (precision_recall_curve, PrecisionRecallDisplay)\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05cf9224-cdee-4444-821e-374d197bd960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_pred, y_true):\n",
    "  print(\"f1 score: \", f1_score(y_true, y_pred))\n",
    "  print(\"accuracy: \", accuracy_score(y_true, y_pred))\n",
    "  print(\"precision:\", precision_score(y_true, y_pred, zero_division=1))\n",
    "  print(\"recall: \", recall_score(y_true, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61865434-0cf0-4070-affd-f1d28f17a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "path_train = \"../../dataset/train_bert_new_4.csv\"\n",
    "path_test = \"../../dataset/test_bert_new_4.csv\"\n",
    "\n",
    "df_train = pd.read_csv(path_train)\n",
    "df_test = pd.read_csv(path_test)\n",
    "\n",
    "x_train = df_train['text'].tolist()\n",
    "x_test = df_test['text'].tolist()\n",
    "y_train = df_train['prediction'].tolist()\n",
    "y_test = df_test['prediction'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed42cd0-42ca-4e76-a1f1-eadb6e472446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    return tokenizer(sentences, padding=True, truncation=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e1a1f7-dba3-4ed6-88f5-b28358a7113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokenized = tokenize(x_train)\n",
    "x_test_tokenized = tokenize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ea1cf7-ed46-4af8-87eb-437e9c3ba2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 16s 372ms/step - loss: 0.7385 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 3s 371ms/step - loss: 0.6580 - accuracy: 0.6204\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 3s 373ms/step - loss: 0.6805 - accuracy: 0.5556\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 3s 376ms/step - loss: 0.6655 - accuracy: 0.6574\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 3s 373ms/step - loss: 0.6592 - accuracy: 0.6481\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 3s 376ms/step - loss: 0.6651 - accuracy: 0.5833\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 3s 376ms/step - loss: 0.6495 - accuracy: 0.6944\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 3s 373ms/step - loss: 0.6342 - accuracy: 0.7130\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 3s 375ms/step - loss: 0.6251 - accuracy: 0.7315\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 3s 375ms/step - loss: 0.6267 - accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 3s 376ms/step - loss: 0.6222 - accuracy: 0.7407\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 3s 379ms/step - loss: 0.6324 - accuracy: 0.6944\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 3s 379ms/step - loss: 0.6225 - accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 3s 379ms/step - loss: 0.6038 - accuracy: 0.7593\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.6117 - accuracy: 0.6852\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.6047 - accuracy: 0.7222\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 3s 382ms/step - loss: 0.6036 - accuracy: 0.6852\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 3s 384ms/step - loss: 0.5807 - accuracy: 0.8148\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 3s 384ms/step - loss: 0.5862 - accuracy: 0.7407\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 3s 388ms/step - loss: 0.5744 - accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 3s 390ms/step - loss: 0.6098 - accuracy: 0.6944\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 3s 394ms/step - loss: 0.5993 - accuracy: 0.7315\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 3s 397ms/step - loss: 0.5844 - accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 3s 392ms/step - loss: 0.6073 - accuracy: 0.7222\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 3s 391ms/step - loss: 0.5953 - accuracy: 0.7315\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 3s 393ms/step - loss: 0.5649 - accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 3s 400ms/step - loss: 0.5775 - accuracy: 0.7130\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 3s 397ms/step - loss: 0.5704 - accuracy: 0.7407\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 3s 398ms/step - loss: 0.5661 - accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 3s 402ms/step - loss: 0.5657 - accuracy: 0.7870\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 3s 406ms/step - loss: 0.5829 - accuracy: 0.6852\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 3s 403ms/step - loss: 0.5474 - accuracy: 0.7870\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 3s 401ms/step - loss: 0.5525 - accuracy: 0.8056\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 3s 404ms/step - loss: 0.5498 - accuracy: 0.7870\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 3s 409ms/step - loss: 0.5458 - accuracy: 0.7593\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 3s 407ms/step - loss: 0.5516 - accuracy: 0.7963\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 3s 406ms/step - loss: 0.5644 - accuracy: 0.7870\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 3s 405ms/step - loss: 0.5527 - accuracy: 0.8148\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 3s 407ms/step - loss: 0.5583 - accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.5637 - accuracy: 0.7222\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 3s 412ms/step - loss: 0.5257 - accuracy: 0.8241\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 3s 412ms/step - loss: 0.5609 - accuracy: 0.7315\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 3s 407ms/step - loss: 0.5557 - accuracy: 0.7778\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 3s 413ms/step - loss: 0.5359 - accuracy: 0.7593\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 3s 413ms/step - loss: 0.5538 - accuracy: 0.7593\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 3s 413ms/step - loss: 0.5304 - accuracy: 0.7778\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 3s 412ms/step - loss: 0.5288 - accuracy: 0.7963\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 3s 414ms/step - loss: 0.5472 - accuracy: 0.7407\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 3s 413ms/step - loss: 0.5176 - accuracy: 0.8426\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 3s 412ms/step - loss: 0.5218 - accuracy: 0.8056\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 3s 413ms/step - loss: 0.5358 - accuracy: 0.7407\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 0.5614 - accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 3s 418ms/step - loss: 0.5136 - accuracy: 0.8333\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.5286 - accuracy: 0.7685\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.5127 - accuracy: 0.7963\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 3s 411ms/step - loss: 0.5067 - accuracy: 0.8148\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.5206 - accuracy: 0.7870\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 3s 411ms/step - loss: 0.5115 - accuracy: 0.7870\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.5180 - accuracy: 0.7685\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 3s 411ms/step - loss: 0.5239 - accuracy: 0.7593\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.5103 - accuracy: 0.7870\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.5083 - accuracy: 0.7685\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.4992 - accuracy: 0.7685\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 3s 408ms/step - loss: 0.5336 - accuracy: 0.7593\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 3s 413ms/step - loss: 0.5106 - accuracy: 0.7963\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.4976 - accuracy: 0.8056\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.4955 - accuracy: 0.8241\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 3s 409ms/step - loss: 0.5067 - accuracy: 0.8056\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 3s 408ms/step - loss: 0.5039 - accuracy: 0.7870\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 3s 416ms/step - loss: 0.4994 - accuracy: 0.8148\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 0.4855 - accuracy: 0.8148\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 3s 416ms/step - loss: 0.5104 - accuracy: 0.8056\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.4960 - accuracy: 0.7870\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 3s 418ms/step - loss: 0.5025 - accuracy: 0.8056\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.5151 - accuracy: 0.7870\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.4915 - accuracy: 0.8056\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.4874 - accuracy: 0.8056\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.4839 - accuracy: 0.8241\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.4781 - accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.4855 - accuracy: 0.8241\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 3s 414ms/step - loss: 0.4605 - accuracy: 0.8241\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.4888 - accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.4919 - accuracy: 0.8148\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.5096 - accuracy: 0.8056\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.4735 - accuracy: 0.7963\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 3s 419ms/step - loss: 0.4976 - accuracy: 0.7778\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 3s 448ms/step - loss: 0.5018 - accuracy: 0.8056\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 3s 450ms/step - loss: 0.4832 - accuracy: 0.7963\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.4827 - accuracy: 0.7778\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.4764 - accuracy: 0.8519\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.4660 - accuracy: 0.8241\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 3s 466ms/step - loss: 0.4598 - accuracy: 0.8426\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.4735 - accuracy: 0.8056\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 0.4689 - accuracy: 0.7963\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.4754 - accuracy: 0.7963\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 0.5116 - accuracy: 0.7963\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.4808 - accuracy: 0.7870\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 0.4940 - accuracy: 0.7593\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 4s 570ms/step - loss: 0.4671 - accuracy: 0.8426\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 3s 416ms/step - loss: 0.4503 - accuracy: 0.8241\n"
     ]
    }
   ],
   "source": [
    "class BERTForClassification(tf.keras.Model):\n",
    "    def __init__(self, bert_model, num_classes, linear_units=512):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "\n",
    "        self.bert.trainable = False\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(linear_units, activation='relu', trainable=True)\n",
    "        self.dense = tf.keras.layers.Dense(num_classes, activation='softmax', trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.bert(inputs)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        linear_output = self.linear(pooled_output) \n",
    "        logits = self.dense(linear_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "classifier = BERTForClassification(model, num_classes)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(x_train_tokenized), y_train)).shuffle(100, seed=42).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(x_test_tokenized), y_test)).batch(16)\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = classifier.fit(\n",
    "    train_dataset,\n",
    "    epochs=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da1be023-11ae-4dac-a96c-737498b65d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 5s 348ms/step - loss: 0.4415 - accuracy: 0.8519\n",
      "3/3 [==============================] - 4s 467ms/step - loss: 0.5073 - accuracy: 0.7292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5072969794273376, 0.7291666865348816]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(train_dataset)\n",
    "classifier.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57cb4fc-710e-4da4-a236-2f0cb8411847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 461ms/step\n",
      "Accuracy: 0.7291667\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(test_dataset)\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_probs = tf.nn.softmax(predictions)  \n",
    "y_pred_class = tf.argmax(predictions, axis=1)  \n",
    "# y_pred_thresholded = tf.where(y_pred_probs[:, 1] > threshold, 1, y_pred_class)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_class, y_test), dtype=tf.float32))\n",
    "print(\"Accuracy:\", accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0740a934-4f45-4489-a60e-c81a5b8e6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.6829268292682927\n",
      "accuracy:  0.7291666666666666\n",
      "precision: 0.5833333333333334\n",
      "recall:  0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "results = metrics(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0671563f-795d-423e-b7a2-e4cbf308bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/73\n",
      "7/7 [==============================] - 12s 408ms/step - loss: 0.6924 - accuracy: 0.5000\n",
      "Epoch 2/73\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.6909 - accuracy: 0.5185\n",
      "Epoch 3/73\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.6889 - accuracy: 0.5185\n",
      "Epoch 4/73\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.6837 - accuracy: 0.5556\n",
      "Epoch 5/73\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.6874 - accuracy: 0.5463\n",
      "Epoch 6/73\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.6837 - accuracy: 0.6111\n",
      "Epoch 7/73\n",
      "7/7 [==============================] - 3s 412ms/step - loss: 0.6782 - accuracy: 0.6759\n",
      "Epoch 8/73\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.6758 - accuracy: 0.6111\n",
      "Epoch 9/73\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.6733 - accuracy: 0.6574\n",
      "Epoch 10/73\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.6712 - accuracy: 0.6111\n",
      "Epoch 11/73\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.6665 - accuracy: 0.6667\n",
      "Epoch 12/73\n",
      "7/7 [==============================] - 3s 412ms/step - loss: 0.6613 - accuracy: 0.6852\n",
      "Epoch 13/73\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.6435 - accuracy: 0.7315\n",
      "Epoch 14/73\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.6465 - accuracy: 0.7130\n",
      "Epoch 15/73\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.6560 - accuracy: 0.6296\n",
      "Epoch 16/73\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.6390 - accuracy: 0.6759\n",
      "Epoch 17/73\n",
      "7/7 [==============================] - 3s 414ms/step - loss: 0.6351 - accuracy: 0.7037\n",
      "Epoch 18/73\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.6205 - accuracy: 0.7130\n",
      "Epoch 19/73\n",
      "7/7 [==============================] - 3s 426ms/step - loss: 0.6158 - accuracy: 0.7315\n",
      "Epoch 20/73\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.5999 - accuracy: 0.7407\n",
      "Epoch 21/73\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.6072 - accuracy: 0.7778\n",
      "Epoch 22/73\n",
      "7/7 [==============================] - 3s 418ms/step - loss: 0.5831 - accuracy: 0.7593\n",
      "Epoch 23/73\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 0.6009 - accuracy: 0.7037\n",
      "Epoch 24/73\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.5748 - accuracy: 0.7500\n",
      "Epoch 25/73\n",
      "7/7 [==============================] - 3s 428ms/step - loss: 0.5955 - accuracy: 0.6759\n",
      "Epoch 26/73\n",
      "7/7 [==============================] - 3s 410ms/step - loss: 0.5546 - accuracy: 0.7222\n",
      "Epoch 27/73\n",
      "7/7 [==============================] - 3s 470ms/step - loss: 0.5556 - accuracy: 0.7407\n",
      "Epoch 28/73\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.5863 - accuracy: 0.7407\n",
      "Epoch 29/73\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.5553 - accuracy: 0.7315\n",
      "Epoch 30/73\n",
      "7/7 [==============================] - 3s 451ms/step - loss: 0.5531 - accuracy: 0.7222\n",
      "Epoch 31/73\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.5323 - accuracy: 0.7778\n",
      "Epoch 32/73\n",
      "7/7 [==============================] - 3s 421ms/step - loss: 0.5361 - accuracy: 0.7870\n",
      "Epoch 33/73\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.5158 - accuracy: 0.7407\n",
      "Epoch 34/73\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.5059 - accuracy: 0.7778\n",
      "Epoch 35/73\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.5003 - accuracy: 0.7778\n",
      "Epoch 36/73\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.4987 - accuracy: 0.7593\n",
      "Epoch 37/73\n",
      "7/7 [==============================] - 3s 429ms/step - loss: 0.5111 - accuracy: 0.7315\n",
      "Epoch 38/73\n",
      "7/7 [==============================] - 3s 420ms/step - loss: 0.4650 - accuracy: 0.7870\n",
      "Epoch 39/73\n",
      "7/7 [==============================] - 3s 445ms/step - loss: 0.4804 - accuracy: 0.7963\n",
      "Epoch 40/73\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.4945 - accuracy: 0.7685\n",
      "Epoch 41/73\n",
      "7/7 [==============================] - 3s 433ms/step - loss: 0.4638 - accuracy: 0.7685\n",
      "Epoch 42/73\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 0.4605 - accuracy: 0.8148\n",
      "Epoch 43/73\n",
      "7/7 [==============================] - 3s 430ms/step - loss: 0.4624 - accuracy: 0.7963\n",
      "Epoch 44/73\n",
      "7/7 [==============================] - 3s 474ms/step - loss: 0.4162 - accuracy: 0.8426\n",
      "Epoch 45/73\n",
      "7/7 [==============================] - 3s 435ms/step - loss: 0.4513 - accuracy: 0.8241\n",
      "Epoch 46/73\n",
      "7/7 [==============================] - 3s 423ms/step - loss: 0.4456 - accuracy: 0.7870\n",
      "Epoch 47/73\n",
      "7/7 [==============================] - 3s 434ms/step - loss: 0.4402 - accuracy: 0.8056\n",
      "Epoch 48/73\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.4267 - accuracy: 0.8056\n",
      "Epoch 49/73\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.4644 - accuracy: 0.8056\n",
      "Epoch 50/73\n",
      "7/7 [==============================] - 3s 460ms/step - loss: 0.3871 - accuracy: 0.8241\n",
      "Epoch 51/73\n",
      "7/7 [==============================] - 3s 414ms/step - loss: 0.4465 - accuracy: 0.8241\n",
      "Epoch 52/73\n",
      "7/7 [==============================] - 3s 459ms/step - loss: 0.4542 - accuracy: 0.7870\n",
      "Epoch 53/73\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.4005 - accuracy: 0.8148\n",
      "Epoch 54/73\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.4877 - accuracy: 0.7407\n",
      "Epoch 55/73\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.4295 - accuracy: 0.8426\n",
      "Epoch 56/73\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.4533 - accuracy: 0.8241\n",
      "Epoch 57/73\n",
      "7/7 [==============================] - 3s 414ms/step - loss: 0.4471 - accuracy: 0.8148\n",
      "Epoch 58/73\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.4039 - accuracy: 0.8611\n",
      "Epoch 59/73\n",
      "7/7 [==============================] - 3s 431ms/step - loss: 0.3987 - accuracy: 0.8333\n",
      "Epoch 60/73\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.4129 - accuracy: 0.8148\n",
      "Epoch 61/73\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.4175 - accuracy: 0.8241\n",
      "Epoch 62/73\n",
      "7/7 [==============================] - 3s 425ms/step - loss: 0.3767 - accuracy: 0.8519\n",
      "Epoch 63/73\n",
      "7/7 [==============================] - 3s 424ms/step - loss: 0.4387 - accuracy: 0.8426\n",
      "Epoch 64/73\n",
      "7/7 [==============================] - 3s 452ms/step - loss: 0.3749 - accuracy: 0.8148\n",
      "Epoch 65/73\n",
      "7/7 [==============================] - 3s 437ms/step - loss: 0.3526 - accuracy: 0.8704\n",
      "Epoch 66/73\n",
      "7/7 [==============================] - 3s 441ms/step - loss: 0.3583 - accuracy: 0.8981\n",
      "Epoch 67/73\n",
      "7/7 [==============================] - 3s 415ms/step - loss: 0.4282 - accuracy: 0.8333\n",
      "Epoch 68/73\n",
      "7/7 [==============================] - 3s 447ms/step - loss: 0.3765 - accuracy: 0.8333\n",
      "Epoch 69/73\n",
      "7/7 [==============================] - 3s 427ms/step - loss: 0.3599 - accuracy: 0.8519\n",
      "Epoch 70/73\n",
      "7/7 [==============================] - 3s 422ms/step - loss: 0.4004 - accuracy: 0.8241\n",
      "Epoch 71/73\n",
      "7/7 [==============================] - 3s 440ms/step - loss: 0.3836 - accuracy: 0.8426\n",
      "Epoch 72/73\n",
      "7/7 [==============================] - 3s 461ms/step - loss: 0.3521 - accuracy: 0.8611\n",
      "Epoch 73/73\n",
      "7/7 [==============================] - 3s 453ms/step - loss: 0.3848 - accuracy: 0.8519\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class BERTForClassification(tf.keras.Model):\n",
    "    def __init__(self, bert_model, num_classes, linear_units=512, additional_linear_units=256, dropout_rate=0.1, trainable_layers=None):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.trainable_layers = trainable_layers\n",
    "\n",
    "\n",
    "        self.bert.trainable = False\n",
    "\n",
    "\n",
    "        if trainable_layers is not None:\n",
    "            for layer in self.bert.layers[-trainable_layers:]:\n",
    "                layer.trainable = True\n",
    "\n",
    "        self.linear1 = tf.keras.layers.Dense(linear_units, activation='relu')\n",
    "        self.linear2 = tf.keras.layers.Dense(additional_linear_units, activation='relu') \n",
    "        self.multihead_attention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64, dropout=dropout_rate)\n",
    "        self.dense = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        outputs = self.bert(inputs, training=training)  \n",
    "        pooled_output = outputs.pooler_output\n",
    "        linear_output1 = self.linear1(pooled_output)  \n",
    "        linear_output2 = self.linear2(linear_output1) \n",
    "        linear_output2 = tf.expand_dims(linear_output2, axis=1) \n",
    "        attention_output = self.multihead_attention(linear_output2, linear_output2) \n",
    "        attention_output = tf.squeeze(attention_output, axis=1) \n",
    "        logits = self.dense(attention_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "trainable_layers = 10\n",
    "\n",
    "classifier = BERTForClassification(model, num_classes, trainable_layers=trainable_layers)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(x_train_tokenized), y_train)).shuffle(100, seed = 42).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(x_test_tokenized), y_test)).batch(16)\n",
    "\n",
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = classifier.fit(\n",
    "    train_dataset,\n",
    "    epochs=73\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742a971d-ccf3-47ef-a205-b5fb059a22b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 4s 456ms/step\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(test_dataset)\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "y_pred_probs = tf.nn.softmax(predictions)  \n",
    "y_pred_class = tf.argmax(predictions, axis=1)  \n",
    "# y_pred_thresholded = tf.where(y_pred_probs[:, 1] > threshold, 1, y_pred_class)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred_class, y_test), dtype=tf.float32))\n",
    "print(\"Accuracy:\", accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "966c559b-fd75-4692-9ea2-caba3f6622c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.6666666666666666\n",
      "accuracy:  0.75\n",
      "precision: 0.5\n",
      "recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e65af2-9d67-43ec-8f3c-4a5fb9acb61a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
